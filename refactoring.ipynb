{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load bitsandbytes native library: /home/users/aas146/miniconda3/envs/aayush_env/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: cannot open shared object file: No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/aas146/miniconda3/envs/aayush_env/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 85, in <module>\n",
      "    lib = get_native_library()\n",
      "  File \"/home/users/aas146/miniconda3/envs/aayush_env/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 72, in get_native_library\n",
      "    dll = ct.cdll.LoadLibrary(str(binary_path))\n",
      "  File \"/home/users/aas146/miniconda3/envs/aayush_env/lib/python3.10/ctypes/__init__.py\", line 452, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/home/users/aas146/miniconda3/envs/aayush_env/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: /home/users/aas146/miniconda3/envs/aayush_env/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "\n",
    "from training_models import MyClipEnsemble\n",
    "\n",
    "from datasets import collate_fn_image, ImageDataset, EnsembleImageDataset\n",
    "from poison_utils import L2_norm\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should print: True\n",
    "print(torch.version.cuda)         # Should match CUDA 12.1 or similar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"mini_MathVista_grid\"\n",
    "method = \"i2i_EnsembleAttack\"\n",
    "args = {\n",
    "    \"model\": \"clip\",\n",
    "    \"poison_save_pth\": f\"./data/poisons/{dataset_name}+{method}\",\n",
    "    \"iter_attack\": 100,\n",
    "    \"lr_attack\": 0.5,\n",
    "    # \"base_data_pth\": f\"data/{dataset_name}/base\",\n",
    "    \"base_data_pth\": f\"data/{dataset_name}/base_512\",\n",
    "    \"target_data_pth\": f\"data/{dataset_name}/target\",\n",
    "    \"questions_pth\": f\"data/{dataset_name}/questions.json\",\n",
    "    \"temperature\": 0,\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"eps\": 8,\n",
    "}\n",
    "def read_json(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# encoder_model = MyClip()\n",
    "encoder_model = MyClipEnsemble()\n",
    "device = encoder_model.device\n",
    "\n",
    "question_json = read_json(args[\"questions_pth\"])\n",
    "pids = question_json.keys()\n",
    "\n",
    "\n",
    "\n",
    "base_caps = read_json(os.path.join(args[\"base_data_pth\"], \"caps.json\"))\n",
    "target_caps = read_json(os.path.join(args[\"target_data_pth\"], \"caps.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dataset = ImageDataset(base_caps[\"annotations\"])\n",
    "# target_dataset = ImageDataset(target_caps[\"annotations\"])\n",
    "base_dataset = EnsembleImageDataset(base_caps[\"annotations\"])\n",
    "target_dataset = EnsembleImageDataset(target_caps[\"annotations\"])\n",
    "\n",
    "base_dataloader = torch.utils.data.DataLoader(\n",
    "    base_dataset, batch_size=1, \n",
    "    shuffle=False, collate_fn=collate_fn_image\n",
    ")\n",
    "\n",
    "target_dataloader = torch.utils.data.DataLoader(\n",
    "    target_dataset, batch_size=1, \n",
    "    shuffle=False, collate_fn=collate_fn_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_img(img, caption):\n",
    "    print(caption)\n",
    "    plt.imshow(img.squeeze(0).permute(1,2,0))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i2i_attack(model, image_base, image_target, iters=100, lr=1/255, eps=8):\n",
    "      '''\n",
    "      optimizing x_adv to minimize emb_dist( img_embed of x_adv, img_embed of image_target ) within Lp constraint using PGD\n",
    "\n",
    "      model: model class with image embedding functionality (e.g. CLIP, EVA)\n",
    "      image_base, image_target: images between [0,1] \n",
    "      emb_dist: the distance metrics for vision embedding (such as L2): take a batch of bs image pairs as input, \\\n",
    "            and output EACH of pair-wise distances of the whole batch (size = [bs])\n",
    "\n",
    "      eps: for Lp constraint\n",
    "      lr: the step size. The update is grad.sign * lr\n",
    "      diff_aug: using differentiable augmentation, e.g. RandomResizeCrop\n",
    "\n",
    "      return: X_adv between [0,1]\n",
    "      '''\n",
    "\n",
    "      bs = image_base.size(0)\n",
    "      device = image_base.device\n",
    "\n",
    "      with torch.no_grad():\n",
    "            embedding_targets = model.encode_image(image_target)\n",
    "            embedding_targets = embedding_targets / embedding_targets.norm(dim=-1, keepdim=True)\n",
    "\n",
    "      X_adv = image_base.clone().detach()\n",
    "      X_adv.requires_grad_(True) \n",
    "\n",
    "      loss_best = 1e8\n",
    "      X_adv_best = X_adv.clone().detach()\n",
    "\n",
    "      # for i in tqdm(range(iters), leave=False):\n",
    "      for i in range(iters):\n",
    "            embs = model.encode_image(X_adv)\n",
    "            embs = embs / embs.norm(dim=-1, keepdim=True)  # Normalize embeddings\n",
    "\n",
    "            loss = L2_norm(embs, embedding_targets)\n",
    "            # loss = torch.mean(torch.sum(embs * embedding_targets, dim=1))\n",
    "\n",
    "            if loss < loss_best:\n",
    "                  loss_best = loss.clone().detach()\n",
    "                  X_adv_best = X_adv.clone().detach()\n",
    "\n",
    "            # optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # print losses at increments\n",
    "            if i% max(int(iters/20),1) == 0:\n",
    "                  # print('Iter :{} loss:{:.4f}, lr * 255:{:.4f}'.format(i,loss.item()/bs, scheduler.get_last_lr()[0]*255))\n",
    "                  print('Iter :{} loss:{:.4f}, lr * 255:{:.4f}'.format(i,loss.item()/bs, lr*255))\n",
    "\n",
    "            grad = X_adv.grad\n",
    "            assert grad != None\n",
    "            grad = grad / torch.mean(torch.abs(grad), dim=(1,2,3), keepdim=True)           \n",
    "            \n",
    "            perturbation = lr * grad.sign()\n",
    "            # print(perturbation.shape)\n",
    "            X_adv.data = X_adv.data.detach() + perturbation\n",
    "            X_adv.data = torch.minimum(torch.maximum(X_adv, image_base - eps), image_base + eps) \n",
    "            X_adv.data = X_adv.data.clamp(0,255)\n",
    "            X_adv.grad = None  \n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                  print('Encounter nan loss at iteration {}'.format(i))\n",
    "                  break                 \n",
    "\n",
    "      print('Best Total loss:{:.4f}'.format(loss.item()))\n",
    "\n",
    "      return X_adv_best, loss_best\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGAImageAttack(model, image, cap, iters=100, lr=1/255, eps=8):\n",
    "      '''\n",
    "      optimizing x_adv to maximize emb_dist( img_embed of x_adv, text_embed of captions ) within Lp constraint using PGD\n",
    "\n",
    "      model: model class with image and text embedding functionality (e.g. CLIP, EVA)\n",
    "      image, cap: image between [0,255] (float) caption dict for that image\n",
    "      emb_dist: the distance metrics for vision embedding (such as L2): take a batch of bs image pairs as input, \\\n",
    "            and output EACH of pair-wise distances of the whole batch (size = [bs])\n",
    "\n",
    "      eps: for Lp constraint\n",
    "      lr: the step size. The update is grad.sign * lr\n",
    "\n",
    "      return: X_adv between [0,255]\n",
    "      '''\n",
    "\n",
    "      bs = image.size(0)\n",
    "      device = image.device\n",
    "\n",
    "      with torch.no_grad():\n",
    "            embedding_targets = model.encode_text(cap['caption'])\n",
    "            embedding_targets = embedding_targets / embedding_targets.norm(dim=-1, keepdim=True)\n",
    "\n",
    "      X_adv = image.clone().detach()\n",
    "      X_adv.requires_grad_(True) \n",
    "\n",
    "      loss_best = 1e8\n",
    "      X_adv_best = X_adv.clone().detach()\n",
    "\n",
    "      # for i in tqdm(range(iters), leave=False):\n",
    "      for i in range(iters):\n",
    "            embs = model.encode_image(X_adv)\n",
    "            embs = embs / embs.norm(dim=-1, keepdim=True)  # Normalize embeddings\n",
    "\n",
    "            loss = -L2_norm(embs, embedding_targets)\n",
    "\n",
    "            if loss < loss_best:\n",
    "                  loss_best = loss.clone().detach()\n",
    "                  X_adv_best = X_adv.clone().detach()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # print losses at increments\n",
    "            if i% max(int(iters/20),1) == 0:\n",
    "                  print('Iter :{} loss:{:.4f}, lr * 255:{:.4f}'.format(i,loss.item()/bs, lr*255))\n",
    "\n",
    "            grad = X_adv.grad\n",
    "            assert grad != None\n",
    "            grad = grad / torch.mean(torch.abs(grad), dim=(1,2,3), keepdim=True)           \n",
    "            \n",
    "            perturbation = lr * grad.sign()\n",
    "            # print(perturbation.shape)\n",
    "            X_adv.data = X_adv.data.detach() - perturbation\n",
    "            X_adv.data = torch.minimum(torch.maximum(X_adv, image_base - eps), image_base + eps) \n",
    "            X_adv.data = X_adv.data.clamp(0,255)\n",
    "            X_adv.grad = None  \n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                  print('Encounter nan loss at iteration {}'.format(i))\n",
    "                  break                 \n",
    "\n",
    "      print('Best Total loss:{:.4f}'.format(loss.item()))\n",
    "\n",
    "      return X_adv_best, loss_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i2i_EnsembleAttack(model, image, target, iters=100, lr=1/255, eps=8):\n",
    "      '''\n",
    "      optimizing x_adv to maximize emb_dist( img_embed of x_adv, text_embed of captions ) within Lp constraint using PGD\n",
    "\n",
    "      model: model class with image and text embedding functionality (e.g. CLIP, EVA)\n",
    "      image, cap: image between [0,255] (float) caption dict for that image\n",
    "      emb_dist: the distance metrics for vision embedding (such as L2): take a batch of bs image pairs as input, \\\n",
    "            and output EACH of pair-wise distances of the whole batch (size = [bs])\n",
    "\n",
    "      eps: for Lp constraint\n",
    "      lr: the step size. The update is grad.sign * lr\n",
    "\n",
    "      return: X_adv between [0,255]\n",
    "      '''\n",
    "\n",
    "      bs = image.size(0)\n",
    "      device = image.device\n",
    "\n",
    "      with torch.no_grad():\n",
    "            embedding_targets = model.encode_image(target)\n",
    "\n",
    "      X_adv = image.clone().detach()\n",
    "      X_adv.requires_grad_(True) \n",
    "\n",
    "      loss_best = -1e8\n",
    "      X_adv_best = X_adv.clone().detach()\n",
    "\n",
    "      # for i in tqdm(range(iters), leave=False):\n",
    "      for i in range(iters):\n",
    "            embs = model.encode_image(X_adv, use_grad=True)\n",
    "\n",
    "            # loss = L2_norm(embs, embedding_targets)\n",
    "            grad, loss = model.get_gradients(embs, embedding_targets, X_adv) \n",
    "\n",
    "            if loss > loss_best:\n",
    "                  loss_best = loss.clone().detach()\n",
    "                  X_adv_best = X_adv.clone().detach()\n",
    "\n",
    "            # print losses at increments\n",
    "            if i% max(int(iters/20),1) == 0:\n",
    "                  print('Iter :{} loss:{:.4f}, lr:{:.4f}'.format(i,loss.item()/bs, lr))\n",
    "\n",
    "            \n",
    "            perturbation = lr * grad.sign() / 255.0\n",
    "            # print(perturbation.shape)\n",
    "            with torch.no_grad():\n",
    "                  X_adv = X_adv + perturbation\n",
    "                  X_adv = torch.min(torch.max(X_adv, image_base - eps/255.0), image_base + eps/255.0)\n",
    "                  X_adv = torch.clamp(X_adv, 0, 1)\n",
    "            X_adv.requires_grad_(True)\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                  print('Encounter nan loss at iteration {}'.format(i))\n",
    "                  break                 \n",
    "\n",
    "      print('Best Total loss:{:.4f}'.format(loss.item()))\n",
    "\n",
    "      # return X_adv.clone().detach(), loss_best\n",
    "      return X_adv_best, loss_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss gets logits and maximizes entropy of each generated word for image caption\n",
    "\n",
    "# def MaximizeInformationEntropyAttack(model, image, cap, iters=100, lr=1/255, eps=8):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGA Image Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# ###### Running SGA Image Attack ######\n",
    "# original_sizes_list = []\n",
    "# X_adv_list = []\n",
    "# all_losses = []\n",
    "# loss_attack_list = []\n",
    "\n",
    "# target_path = os.path.join(args['poison_save_pth'], \"SGA\")\n",
    "\n",
    "# if not os.path.exists(target_path):\n",
    "#     os.makedirs(target_path)\n",
    "# saved_images = set(os.listdir(target_path))\n",
    "# saved_image_ids = {int(fname.split('.')[0]) for fname in saved_images if fname.endswith(('.png', '.jpg', '.jpeg'))}\n",
    "\n",
    "\n",
    "# for i, (image_base, base_cap) in  tqdm(enumerate(base_dataloader), desc=f\"Processing all images\", total=len(base_dataloader)):\n",
    "#     if base_cap['name'] in saved_image_ids:\n",
    "#             print(f\"{base_cap['name']} already processed for {target_cap['name']}, skipping...\")\n",
    "#             continue\n",
    "\n",
    "#     print('image name = ', base_cap['name'])\n",
    "#     image_base = image_base.to(device)\n",
    "\n",
    "#     X_adv, loss_attack = SGAImageAttack(\n",
    "#             model=encoder_model,\n",
    "#             image=image_base,\n",
    "#             cap=base_cap,\n",
    "#             iters=args['iter_attack'],\n",
    "#             lr=args['lr_attack'],\n",
    "#             eps=args['eps']\n",
    "#     )\n",
    "\n",
    "\n",
    "#     ###### Save poisoned images after each batch ######\n",
    "#     img_pth = os.path.join(target_path, f\"{base_cap['name']}.png\")\n",
    "#     image_to_save = X_adv/255.0\n",
    "#     print()\n",
    "#     if base_cap['name'] not in saved_image_ids:  # Only save if it doesn't already exist\n",
    "#         print(\"Max Pixel Difference between Adversarial Image and Base *255:\", round(torch.max(torch.abs(X_adv-image_base)).item(), 4))\n",
    "#         save_image(image_to_save.cpu(), img_pth)\n",
    "#         print(f\"Saved poisoned image {base_cap['name']} to {img_pth}\") # mathvista\n",
    "\n",
    "#     # show_img(((X_adv-image_base).to(torch.uint8).cpu()*10), (\"Adversarial Noise\", img_pth))\n",
    "#     # show_img(image_to_save.cpu(), (\"Adversarial Image\", img_pth))\n",
    "\n",
    "        \n",
    "\n",
    "# print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i2i attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Running i2i attack ######\n",
    "# original_sizes_list = []\n",
    "# X_adv_list = []\n",
    "# all_losses = []\n",
    "# loss_attack_list = []\n",
    "# start_idx = 0\n",
    "# end_idx = 0\n",
    "# # for j, (image_target, target_cap) in  tqdm(enumerate(target_dataloader)):\n",
    "# for j, (image_target, target_cap) in  tqdm(enumerate(target_dataloader), desc=\"Target Dataloader\", position=0, leave=True):\n",
    "#     target_name = target_cap[\"name\"]\n",
    "#     target_path = os.path.join(args[\"poison_save_pth\"], target_cap[\"name\"])\n",
    "#     if not os.path.exists(target_path):\n",
    "#         os.makedirs(target_path)\n",
    "\n",
    "#     ###### Resume by checking already saved images ######\n",
    "#     saved_images = set(os.listdir(target_path))\n",
    "#     saved_image_ids = {int(fname.split('.')[0]) for fname in saved_images if fname.endswith(('.png', '.jpg', '.jpeg'))}\n",
    "\n",
    "#     # show_img(image_target, (\"Working on target:\", target_name))\n",
    "\n",
    "#     for i, (image_base, base_cap) in  tqdm(enumerate(base_dataloader), desc=f\"Processing {target_name}\", total=len(base_dataloader), position=1, leave=False):\n",
    "#         if base_cap['name'] in saved_image_ids:\n",
    "#                 print(f\"{base_cap['name']} already processed for {target_cap['name']}, skipping...\")\n",
    "#                 continue\n",
    "\n",
    "#         print('image name = ', base_cap['name'])\n",
    "#         image_base, image_target = image_base.to(device), image_target.to(device)\n",
    "\n",
    "#         X_adv, loss_attack = i2i_attack(\n",
    "#                 model=encoder_model,\n",
    "#                 image_base=image_base,\n",
    "#                 image_target=image_target,\n",
    "#                 iters=args['iter_attack'],\n",
    "#                 lr=args['lr_attack'],\n",
    "#                 eps=args['eps']\n",
    "#         )\n",
    "\n",
    "\n",
    "#         ###### Save poisoned images after each batch ######\n",
    "#         img_pth = os.path.join(target_path, f\"{base_cap['name']}.png\")\n",
    "#         image_to_save = X_adv/255.0\n",
    "#         print()\n",
    "#         if base_cap['name'] not in saved_image_ids:  # Only save if it doesn't already exist\n",
    "#             print(\"Max Pixel Difference between Adversarial Image and Base *255:\", round(torch.max(torch.abs(X_adv-image_base)).item(), 4))\n",
    "#             save_image(image_to_save.cpu(), img_pth)\n",
    "#             print(f\"Saved poisoned image {base_cap['name']} to {img_pth}\") # mathvista\n",
    "\n",
    "#         # show_img(((X_adv-image_base).to(torch.uint8).cpu()*10), (\"Adversarial Noise\", img_pth))\n",
    "#         # show_img(image_to_save.cpu(), (\"Adversarial Image\", img_pth))\n",
    "\n",
    "        \n",
    "\n",
    "# print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i2i Ensemble attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Running i2i attack ######\n",
    "original_sizes_list = []\n",
    "X_adv_list = []\n",
    "all_losses = []\n",
    "loss_attack_list = []\n",
    "start_idx = 0\n",
    "end_idx = 0\n",
    "# for j, (image_target, target_cap) in  tqdm(enumerate(target_dataloader)):\n",
    "for j, (image_target, target_cap) in  tqdm(enumerate(target_dataloader), desc=\"Target Dataloader\", position=0, leave=True):\n",
    "    target_name = target_cap[\"name\"]\n",
    "    target_path = os.path.join(args[\"poison_save_pth\"], target_cap[\"name\"])\n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "\n",
    "    ###### Resume by checking already saved images ######\n",
    "    saved_images = set(os.listdir(target_path))\n",
    "    saved_image_ids = {int(fname.split('.')[0]) for fname in saved_images if fname.endswith(('.png', '.jpg', '.jpeg'))}\n",
    "\n",
    "    # show_img(image_target, (\"Working on target:\", target_name))\n",
    "\n",
    "    for i, (image_base, base_cap) in  tqdm(enumerate(base_dataloader), desc=f\"Processing {target_name}\", total=len(base_dataloader), position=1, leave=False):\n",
    "        if base_cap['name'] in saved_image_ids:\n",
    "                print(f\"{base_cap['name']} already processed for {target_cap['name']}, skipping...\")\n",
    "                continue\n",
    "\n",
    "        print('image name = ', base_cap['name'])\n",
    "        image_base, image_target = image_base.to(device), image_target.to(device)\n",
    "\n",
    "        X_adv, loss_attack = i2i_EnsembleAttack(\n",
    "                model=encoder_model,\n",
    "                image=image_base,\n",
    "                target=image_target,\n",
    "                iters=args['iter_attack'],\n",
    "                lr=args['lr_attack'],\n",
    "                eps=args['eps']\n",
    "        )\n",
    "\n",
    "\n",
    "        ###### Save poisoned images after each batch ######\n",
    "        img_pth = os.path.join(target_path, f\"{base_cap['name']}.png\")\n",
    "        image_to_save = X_adv\n",
    "        print()\n",
    "        if base_cap['name'] not in saved_image_ids:  # Only save if it doesn't already exist\n",
    "            print(\"Max Pixel Difference between Adversarial Image and Base *255:\", torch.max(torch.abs(X_adv-image_base)).item()*255)\n",
    "            save_image(image_to_save.cpu(), img_pth)\n",
    "            print(f\"Saved poisoned image {base_cap['name']} to {img_pth}\") # mathvista\n",
    "\n",
    "        # show_img(((X_adv-image_base).to(torch.uint8).cpu()*10), (\"Adversarial Noise\", img_pth))\n",
    "        # show_img(image_to_save.cpu(), (\"Adversarial Image\", img_pth))\n",
    "\n",
    "        \n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"Here to stop execution for this section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathvista Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacking_model=\"internvl\"\n",
    "captioning_model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "from poison_utils import *\n",
    "\n",
    "from eval_models import internlm, internvl\n",
    "from eval_models import gpt\n",
    "\n",
    "from build_query import create_query_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def verify_response(response):\n",
    "    if isinstance(response, str):\n",
    "        response = response.strip() \n",
    "    if response == \"\" or response == None:\n",
    "        return False\n",
    "    if \"Response Error\" in response:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def evaluate_code(code_string):\n",
    "    # execute_code_and_capture_output\n",
    "    # Backup the original stdout\n",
    "    old_stdout = sys.stdout\n",
    "    \n",
    "    # Redirect stdout to capture the output\n",
    "    new_stdout = io.StringIO()\n",
    "    sys.stdout = new_stdout\n",
    "    \n",
    "    # Try executing the code and capture any exception\n",
    "    error = None\n",
    "    try:\n",
    "        exec(code_string)\n",
    "    except Exception as e:\n",
    "        error = e\n",
    "    \n",
    "    # Restore the original stdout\n",
    "    sys.stdout = old_stdout\n",
    "    \n",
    "    # Get the captured output\n",
    "    captured_output = new_stdout.getvalue()\n",
    "    if isinstance(captured_output, str):\n",
    "        captured_output = captured_output.strip()\n",
    "    \n",
    "    # Return the captured output or error\n",
    "    return captured_output, error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import time\n",
      "import openai\n",
      "from openai import OpenAI\n",
      "import base64\n",
      "\n",
      "# Updated GPT class using OpenAI SDK v1.x\n",
      "class GPT_Model():\n",
      "    def __init__(self, model=\"gpt-3.5-turbo\", api_key=\"\", temperature=0, max_tokens=1024, n=1, patience=1000000, sleep_time=0):\n",
      "        self.model = model\n",
      "        self.api_key = api_key\n",
      "        self.temperature = temperature\n",
      "        self.max_tokens = max_tokens\n",
      "        self.n = n\n",
      "        self.patience = patience\n",
      "        self.sleep_time = sleep_time\n",
      "        self.client = OpenAI(api_key=self.api_key)\n",
      "\n",
      "    def get_response(self, image_path=None, user_prompt=\"\"):\n",
      "        patience = self.patience\n",
      "        max_tokens = self.max_tokens\n",
      "        with open(image_path, \"rb\") as image_file:\n",
      "            base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
      "            data_url = f\"data:image/png;base64,{base64_image}\"\n",
      "        # messages = [\n",
      "        #     {\"role\": \"user\", \"content\": user_prompt},\n",
      "        # ]\n",
      "        messages = [\n",
      "        {\n",
      "            \"role\": \"user\",\n",
      "            \"content\": [\n",
      "                { \"type\": \"text\", \"text\": user_prompt },\n",
      "                { \"type\": \"image_url\", \"image_url\": { \"url\": data_url } }\n",
      "            ]\n",
      "        }\n",
      "        ]\n",
      "        while patience > 0:\n",
      "            patience -= 1\n",
      "            try:\n",
      "                response = self.client.chat.completions.create(\n",
      "                    model=self.model,\n",
      "                    messages=messages,\n",
      "                    temperature=self.temperature,\n",
      "                    max_tokens=max_tokens,\n",
      "                    n=self.n\n",
      "                )\n",
      "\n",
      "                if self.n == 1:\n",
      "                    prediction = response.choices[0].message.content.strip()\n",
      "                    if prediction:\n",
      "                        return prediction\n",
      "                else:\n",
      "                    prediction = [choice.message.content.strip() for choice in response.choices]\n",
      "                    if prediction[0]:\n",
      "                        return prediction\n",
      "\n",
      "            except Exception as e:\n",
      "                print(\"Exception:\", e)\n",
      "                if \"Please reduce the length of the messages or completion\" in str(e):\n",
      "                    max_tokens = int(max_tokens * 0.9)\n",
      "                    print(\"!! Reduce max_tokens to\", max_tokens)\n",
      "                if max_tokens < 8:\n",
      "                    return \"\"\n",
      "                if self.sleep_time > 0:\n",
      "                    time.sleep(self.sleep_time)\n",
      "\n",
      "        return \"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_name = \"mini_MathVista_grid\"\n",
    "import inspect\n",
    "class Args:\n",
    "    def __init__(self, task_name, attacking_model, captioning_model):\n",
    "        # Input\n",
    "        self.poison_data_dir = f'data/poisons/{task_name}'\n",
    "        self.input_file = 'questions.json'\n",
    "        self.task_data_pth = f'data/{task_name}'\n",
    "\n",
    "        # Output\n",
    "        self.output_dir = f'results/{attacking_model}'\n",
    "        self.output_file = f'output_{attacking_model}.json'\n",
    "\n",
    "        # Model\n",
    "        self.model = captioning_model\n",
    "        self.key = \"\"\n",
    "\n",
    "        # Query\n",
    "        self.query_file = None\n",
    "        # self.caption_file = '../data/texts/captions_bard.json'\n",
    "        # self.ocr_file = '../data/texts/ocrs_easyocr.json'\n",
    "        self.shot_type = 'solution'\n",
    "        self.shot_num = 0\n",
    "        self.use_caption = False\n",
    "        self.use_ocr = False\n",
    "\n",
    "        # Other settings\n",
    "        self.rerun = False\n",
    "        self.debug = False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Args({self.__dict__})\"\n",
    "\n",
    "args = Args(task_name, attacking_model, captioning_model)\n",
    "print(inspect.getsource(gpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # load data\n",
    "    input_file = os.path.join(args.task_data_pth, args.input_file)\n",
    "    print(f\"Reading {input_file}...\")\n",
    "    data = read_json(input_file)\n",
    "    # load or create query data\n",
    "    if args.query_file:\n",
    "        query_file = os.path.join(args.task_data_pth, args.query_file)\n",
    "        if os.path.exists(query_file):\n",
    "            print(f\"Loading existing {query_file}...\")\n",
    "            query_data = read_json(query_file)\n",
    "    else:\n",
    "        print(\"\\nCreating new query...\")\n",
    "        # load caption\n",
    "        caption_data = {}\n",
    "        if args.use_caption:\n",
    "            caption_file = args.caption_file\n",
    "            if os.path.exists(caption_file):\n",
    "                print(f\"Reading {caption_file}...\")\n",
    "                try:\n",
    "                    caption_data = read_json(caption_file)[\"texts\"]\n",
    "                    print(\"Caption data loaded.\")\n",
    "                except:\n",
    "                    print(\"Caption data not found!! Please Check.\")                    \n",
    "        # load ocr\n",
    "        ocr_data = {}\n",
    "        if args.use_ocr:\n",
    "            ocr_file = args.ocr_file\n",
    "            if os.path.exists(ocr_file):\n",
    "                print(f\"Reading {ocr_file}...\")\n",
    "                try:\n",
    "                    ocr_data = read_json(ocr_file)[\"texts\"]\n",
    "                    print(\"OCR data loaded.\")\n",
    "                except:\n",
    "                    print(\"OCR data not found!! Please Check.\")\n",
    "        # create query\n",
    "        query_data = create_query_data(data, caption_data, ocr_data, args)\n",
    "\n",
    "    # output file\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    output_file = os.path.join(args.output_dir, args.output_file)\n",
    "    \n",
    "    # load results\n",
    "    if os.path.exists(output_file):\n",
    "        print(\"\\nResults already exist.\")\n",
    "        print(f\"Reading {output_file}...\")\n",
    "        results = read_json(output_file)\n",
    "    else:\n",
    "        results = {}\n",
    "\n",
    "    # load model\n",
    "    print(f\"\\nLoading {args.model}...\")\n",
    "    if args.model == 'bard':\n",
    "        if args.key == '':\n",
    "            print(\"Loading key from environment variable\")\n",
    "            key = os.environ['_BARD_API_KEY']\n",
    "        else:\n",
    "            key = args.key\n",
    "        model = bard.Bard_Model(key)\n",
    "    \n",
    "    elif \"gpt\" in args.model:\n",
    "        if args.key == '':\n",
    "            print(\"Loading token from environment variable\")\n",
    "            key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        else:\n",
    "            key = args.key\n",
    "        model = gpt.GPT_Model(args.model, key)\n",
    "    \n",
    "    elif \"claude\" in args.model:\n",
    "        if args.key == '':\n",
    "            print(\"Loading token from environment variable\")\n",
    "            key = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "        else:\n",
    "            key = args.key\n",
    "        model = claude.Claude_Model(args.model, key)\n",
    "    elif \"internlm\" in args.model:\n",
    "        model = internlm.InternLM_Model()\n",
    "    elif \"llava_one_v\" in args.model:\n",
    "        model = llava_one_v.Llava_One_V()\n",
    "    elif \"internvl\" in args.model:\n",
    "        model = internvl.InternVL_Model()\n",
    "            \n",
    "    print(key)\n",
    "    print(f\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # build final test pid list\n",
    "    test_pids = list(data.keys())\n",
    "    print(\"\\nNumber of test problems in total:\", len(test_pids))\n",
    "\n",
    "    available_directories = [d for d in os.listdir(args.poison_data_dir) if os.path.isdir(os.path.join(args.poison_data_dir, d))]\n",
    "    target_names = read_json(os.path.join(args.task_data_pth, \"target/caps.json\"))\n",
    "    if not all([name in available_directories for name in target_names]):\n",
    "        print(\"Not all targets have directories. Working with:\", available_directories)\n",
    "    target_names = [item[\"name\"] for item in target_names[\"annotations\"] if item[\"name\"] in available_directories]\n",
    "\n",
    "    skip_pids = []\n",
    "    if not args.rerun:\n",
    "        print(\"\\nRemoving problems with existing valid response...\")\n",
    "        for i, name in enumerate(target_names):\n",
    "            skip_pids.append([])\n",
    "            for pid in test_pids:\n",
    "                # print(f\"Checking {pid}...\")\n",
    "                if pid in results and 'response' in results[pid]:\n",
    "                    response = results[pid][name]['response']\n",
    "                    if verify_response(response):\n",
    "                        # print(f\"Valid response found for {pid}.\")\n",
    "                        skip_pids[i].append(pid)\n",
    "    else:\n",
    "        print(\"\\nRerun answer extraction for all problems...\")\n",
    "\n",
    "    test_pids = [[pid for pid in test_pids if pid not in target_skip_pids] for target_skip_pids in skip_pids]\n",
    "    print(\"Number of test problems to run for each target:\", {target_names[i]: len(target_pids) for i, target_pids in enumerate(test_pids)})\n",
    "    # print(test_pids)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # tqdm, enumerate results\n",
    "    for i, target_name in enumerate(target_names):\n",
    "        for _, pid in enumerate(tqdm(test_pids[i])):\n",
    "            problem = data[pid]\n",
    "            query = query_data[pid]\n",
    "            image = problem['image']\n",
    "            image_path = os.path.join(args.poison_data_dir, target_name, image)\n",
    "            response = model.get_response(image_path, query)\n",
    "            if args.debug:\n",
    "                print(\"--------------------------------------------------------------\")\n",
    "            print(f\"\\nGenerating response for {pid}...\")\n",
    "            try:\n",
    "                response = model.get_response(image_path, query)\n",
    "                new_caption = model.get_response(image_path, \"describe what is in this image\")\n",
    "                # print(f\"Response: {response}\")\n",
    "                if pid not in results:\n",
    "                    results[pid] = problem\n",
    "                if \"targets\" not in results[pid]:\n",
    "                    results[pid][\"targets\"] = {}\n",
    "                if target_name not in results[pid][\"targets\"]:\n",
    "                    results[pid][\"targets\"][target_name] = {}\n",
    "\n",
    "                results[pid][\"targets\"][target_name]['query'] = query\n",
    "                results[pid][\"targets\"][target_name]['model_description'] = new_caption\n",
    "                if args.shot_type == 'solution':\n",
    "                    results[pid][\"targets\"][target_name]['response'] = response\n",
    "                else:\n",
    "                    output, error = evaluate_code(response)\n",
    "                    results[pid][\"targets\"][target_name]['response'] = response\n",
    "                    results[pid][\"targets\"][target_name]['execution'] = output\n",
    "                    results[pid][\"targets\"][target_name]['error'] = str(error)\n",
    "                if args.debug:\n",
    "                    print(f\"\\n#Query: \\n{query}\")\n",
    "                    print(f\"\\n#Response: \\n{response}\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(f\"Error in extracting answer for {pid}\")\n",
    "                results[pid][target_name]['error'] = e\n",
    "        \n",
    "            try:\n",
    "                print(f\"Saving results to {output_file}...\")\n",
    "                save_json(results, output_file)\n",
    "                print(f\"Results saved.\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(f\"Error in saving {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from tqdm import tqdm\n",
    "from poison_utils import *\n",
    "\n",
    "# OpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from prompts.ext_ans import demo_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409: #             client = openai.OpenAI(api_key=api_key)\n",
      "410: \n",
      "411: #             response = client.chat.completions.create(\n",
      "412: #                 model=model,\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import linecache\n",
    "# import poison_utils\n",
    "\n",
    "# # Get the path to the module\n",
    "# file_path = poison_utils.__file__  # This gives you the path to poison_utils/__init__.py\n",
    "\n",
    "# # Print lines 409 to 412\n",
    "# for i in range(409, 413):\n",
    "#     line = linecache.getline(file_path, i)\n",
    "#     print(f\"{i}: {line}\", end=\"\")\n",
    "\n",
    "import linecache\n",
    "import poison_utils.updated_init as pu\n",
    "\n",
    "file_path = pu.__file__  # gets the path to the file\n",
    "\n",
    "# Print lines 409 to 412\n",
    "for i in range(409, 413):\n",
    "    print(f\"{i}: {linecache.getline(file_path, i).rstrip()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '145°'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m145\u001b[39;49m\u001b[38;5;130;43;01m\\u00b0\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '145°'"
     ]
    }
   ],
   "source": [
    "print(int(\"145\\u00b0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_extraction(extraction):\n",
    "    extraction = extraction.strip()\n",
    "    if extraction == \"\" or extraction == None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def create_test_prompt(demo_prompt, query, response):\n",
    "    demo_prompt = demo_prompt.strip()\n",
    "    test_prompt = f\"{query}\\n\\n{response}\"\n",
    "    full_prompt = f\"{demo_prompt}\\n\\n{test_prompt}\\n\\nExtracted answer: \"\n",
    "    return full_prompt\n",
    "\n",
    "\n",
    "def extract_answer(response, problem, target_name, model=None, quick_extract=False):\n",
    "    question_type = problem['question_type']\n",
    "    answer_type = problem['answer_type']\n",
    "    choices = problem['choices']\n",
    "    query = problem[\"targets\"][target_name]['query']\n",
    "    pid = problem['pid']\n",
    "\n",
    "    if response == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    if question_type == 'multi_choice' and response in choices:\n",
    "        return response\n",
    "    \n",
    "    if answer_type == \"integer\":\n",
    "        try:\n",
    "            extraction = int(response)\n",
    "            return str(extraction)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if answer_type == \"float\":\n",
    "        try:\n",
    "            extraction = str(float(response))\n",
    "            return extraction\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # quick extraction\n",
    "    if quick_extract:\n",
    "        print(\"Quickly extracting answer...\")\n",
    "        # The answer is \"text\". -> \"text\"\n",
    "        try:\n",
    "            result = re.search(r'The answer is \"(.*)\"\\.', response)\n",
    "            if result:\n",
    "                extraction = result.group(1)\n",
    "                return extraction\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # general extraction\n",
    "    try:\n",
    "        full_prompt = create_test_prompt(demo_prompt, query, response)\n",
    "        # print(f\"full prompt: {full_prompt}\")\n",
    "        # extraction = model.get_chat_response(full_prompt)\n",
    "        extraction = get_chat_response(full_prompt, openai.api_key)\n",
    "        return extraction\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Error in extracting answer for {pid}\")\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def get_mc_letter(choices, answer):\n",
    "    choice = choices.index(answer)\n",
    "    if choice == -1:\n",
    "        raise Exception(\"Multiple choice extraction failed\")\n",
    "    return chr(ord('A') + choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)\n",
    "# model = internvl.InternVL_Model()\n",
    "model = \"internvl_clip_ensemble_i2i\"\n",
    "broad_model = \"internvl\"\n",
    "args = {\n",
    "    \"output_dir\": f\"results/{model}\",\n",
    "    \"output_file\": f\"output_{broad_model}.json\",\n",
    "    \"response_label\": \"response\",\n",
    "    \"llm_engine\": None,\n",
    "    \"number\": 0,\n",
    "    \"quick_extract\": False,\n",
    "    \"rerun\": True, \n",
    "    \"save_every\": 2,\n",
    "    \"output_label\": \"test_output\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "label = args[\"response_label\"]\n",
    "result_file = os.path.join(args[\"output_dir\"], args[\"output_file\"])\n",
    "\n",
    "if args[\"output_label\"] != '':\n",
    "    output_file = result_file.replace('.json', f'_{args[\"output_label\"]}.json')\n",
    "else:\n",
    "    output_file = result_file\n",
    "\n",
    "# read results\n",
    "print(f\"Reading {result_file}...\")\n",
    "results = read_json(result_file)\n",
    "\n",
    "# model = llama_3_1.LLaMA()\n",
    "\n",
    "# full pids\n",
    "full_pids = list(results.keys())\n",
    "if args[\"number\"] > 0:\n",
    "    full_pids = full_pids[:min(args[\"number\"], len(full_pids))]\n",
    "print(\"Number of testing problems:\", len(full_pids))\n",
    "\n",
    "# test pids\n",
    "if args[\"rerun\"]:\n",
    "    test_pids = full_pids\n",
    "else:\n",
    "    test_pids = []\n",
    "    for pid in full_pids:\n",
    "        # print(pid)\n",
    "        if 'extraction' not in results[pid] or not verify_extraction(results[pid]['extraction']):\n",
    "            test_pids.append(pid)\n",
    "\n",
    "\n",
    "test_num = len(test_pids)\n",
    "print(\"Number of problems to run:\", test_num)\n",
    "# print(test_pids)\n",
    "# print(results[0])\n",
    "# Initialize correctness matrix: target_name -> list of 0/1s per question (index matches test_pids)\n",
    "correctness_matrix = {name: [] for name in results[test_pids[0]][\"targets\"].keys()}\n",
    "# tqdm, enumerate results\n",
    "for i, pid in enumerate(tqdm(test_pids)):\n",
    "    # print(pid)\n",
    "    target_names = results[pid][\"targets\"].keys()\n",
    "    for name in target_names:\n",
    "        problem = results[pid]\n",
    "        assert label in problem[\"targets\"][name]\n",
    "        response = problem[\"targets\"][name][label]       \n",
    "\n",
    "        \n",
    "        # extraction  = extract_answer(response, problem, name, model, args.quick_extract)\n",
    "        extraction  = extract_answer(response, problem, name, None, args[\"quick_extract\"])\n",
    "        results[pid][\"targets\"][name]['extraction'] = extraction\n",
    "        answer = \"\"\n",
    "        if problem[\"question_type\"] == \"multi_choice\":\n",
    "            answer = get_mc_letter(problem[\"choices\"], results[pid][\"answer\"]) #which multiple choice question, should work\n",
    "        else: \n",
    "            answer = results[pid][\"answer\"]\n",
    "\n",
    "        is_correct = (answer == extraction)\n",
    "        results[pid][\"targets\"][name]['correct'] = is_correct\n",
    "\n",
    "        # Store result in the matrix\n",
    "        correctness_matrix[name].append(1 if is_correct else 0)\n",
    "        \n",
    "        if i % args[\"save_every\"] == 0 or i == test_num - 1:\n",
    "            print(f\"Saving results to {output_file}...\")\n",
    "            save_json(results, output_file)\n",
    "            print(f\"Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "## Only run to retrieve data in VLM-Poisoning/results/internvl_clip_ensemble_i2i/output_internvl_test_output.json\n",
    "\n",
    "import json\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Path to your saved results file\n",
    "output_file = \"/usr/xtmp/aas146_real/VLM-Poisoning/results/internvl_clip_ensemble_i2i/output_internvl_test_output.json\"  # <- Change this to match your saved file path\n",
    "\n",
    "# Load results\n",
    "results = read_json(output_file)\n",
    "\n",
    "def verify_extraction(extraction):\n",
    "    # Define this function just like in your original script\n",
    "    return extraction is not None and len(str(extraction).strip()) > 0\n",
    "\n",
    "full_pids = list(results.keys())\n",
    "test_pids = [pid for pid in full_pids if 'extraction' not in results[pid] or not verify_extraction(results[pid]['extraction'])]\n",
    "\n",
    "\n",
    "correctness_matrix = {name: [] for name in results[test_pids[0]][\"targets\"].keys()}\n",
    "\n",
    "for pid in test_pids:\n",
    "    for name in results[pid][\"targets\"].keys():\n",
    "        is_correct = results[pid][\"targets\"][name].get(\"correct\", False)\n",
    "        correctness_matrix[name].append(1 if is_correct else 0)\n",
    "\n",
    "# print(correctness_matrix['bar'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Failiure Rates:\n",
      "bar: 45.00%\n",
      "docs: 43.00%\n",
      "tbl: 44.00%\n",
      "synth: 40.00%\n",
      "nat: 43.00%\n",
      "pie: 47.00%\n",
      "sci: 41.00%\n",
      "vlin: 44.00%\n",
      "rdar: 37.00%\n",
      "pzle: 40.00%\n",
      "med: 42.00%\n",
      "sctr: 77.00%\n",
      "\n",
      "Question Failiure Rates:\n",
      "Question 0: 100.00% (0 successes, 12 failures)\n",
      "Question 1: 8.33% (11 successes, 1 failures)\n",
      "Question 2: 0.00% (12 successes, 0 failures)\n",
      "Question 3: 33.33% (8 successes, 4 failures)\n",
      "Question 4: 41.67% (7 successes, 5 failures)\n",
      "Question 5: 16.67% (10 successes, 2 failures)\n",
      "Question 6: 100.00% (0 successes, 12 failures)\n",
      "Question 7: 75.00% (3 successes, 9 failures)\n",
      "Question 8: 0.00% (12 successes, 0 failures)\n",
      "Question 9: 75.00% (3 successes, 9 failures)\n",
      "Question 10: 66.67% (4 successes, 8 failures)\n",
      "Question 11: 66.67% (4 successes, 8 failures)\n",
      "Question 12: 75.00% (3 successes, 9 failures)\n",
      "Question 13: 25.00% (9 successes, 3 failures)\n",
      "Question 14: 0.00% (12 successes, 0 failures)\n",
      "Question 15: 100.00% (0 successes, 12 failures)\n",
      "Question 16: 0.00% (12 successes, 0 failures)\n",
      "Question 17: 0.00% (12 successes, 0 failures)\n",
      "Question 18: 50.00% (6 successes, 6 failures)\n",
      "Question 19: 91.67% (1 successes, 11 failures)\n",
      "Question 20: 0.00% (12 successes, 0 failures)\n",
      "Question 21: 0.00% (12 successes, 0 failures)\n",
      "Question 22: 8.33% (11 successes, 1 failures)\n",
      "Question 23: 0.00% (12 successes, 0 failures)\n",
      "Question 24: 25.00% (9 successes, 3 failures)\n",
      "Question 25: 0.00% (12 successes, 0 failures)\n",
      "Question 26: 100.00% (0 successes, 12 failures)\n",
      "Question 27: 0.00% (12 successes, 0 failures)\n",
      "Question 28: 100.00% (0 successes, 12 failures)\n",
      "Question 29: 41.67% (7 successes, 5 failures)\n",
      "Question 30: 0.00% (12 successes, 0 failures)\n",
      "Question 31: 0.00% (12 successes, 0 failures)\n",
      "Question 32: 0.00% (12 successes, 0 failures)\n",
      "Question 33: 100.00% (0 successes, 12 failures)\n",
      "Question 34: 8.33% (11 successes, 1 failures)\n",
      "Question 35: 100.00% (0 successes, 12 failures)\n",
      "Question 36: 58.33% (5 successes, 7 failures)\n",
      "Question 37: 0.00% (12 successes, 0 failures)\n",
      "Question 38: 50.00% (6 successes, 6 failures)\n",
      "Question 39: 41.67% (7 successes, 5 failures)\n",
      "Question 40: 100.00% (0 successes, 12 failures)\n",
      "Question 41: 8.33% (11 successes, 1 failures)\n",
      "Question 42: 8.33% (11 successes, 1 failures)\n",
      "Question 43: 8.33% (11 successes, 1 failures)\n",
      "Question 44: 100.00% (0 successes, 12 failures)\n",
      "Question 45: 8.33% (11 successes, 1 failures)\n",
      "Question 46: 100.00% (0 successes, 12 failures)\n",
      "Question 47: 100.00% (0 successes, 12 failures)\n",
      "Question 48: 100.00% (0 successes, 12 failures)\n",
      "Question 49: 100.00% (0 successes, 12 failures)\n",
      "Question 50: 33.33% (8 successes, 4 failures)\n",
      "Question 51: 58.33% (5 successes, 7 failures)\n",
      "Question 52: 83.33% (2 successes, 10 failures)\n",
      "Question 53: 8.33% (11 successes, 1 failures)\n",
      "Question 54: 16.67% (10 successes, 2 failures)\n",
      "Question 55: 8.33% (11 successes, 1 failures)\n",
      "Question 56: 83.33% (2 successes, 10 failures)\n",
      "Question 57: 8.33% (11 successes, 1 failures)\n",
      "Question 58: 16.67% (10 successes, 2 failures)\n",
      "Question 59: 100.00% (0 successes, 12 failures)\n",
      "Question 60: 25.00% (9 successes, 3 failures)\n",
      "Question 61: 8.33% (11 successes, 1 failures)\n",
      "Question 62: 91.67% (1 successes, 11 failures)\n",
      "Question 63: 8.33% (11 successes, 1 failures)\n",
      "Question 64: 8.33% (11 successes, 1 failures)\n",
      "Question 65: 91.67% (1 successes, 11 failures)\n",
      "Question 66: 8.33% (11 successes, 1 failures)\n",
      "Question 67: 41.67% (7 successes, 5 failures)\n",
      "Question 68: 100.00% (0 successes, 12 failures)\n",
      "Question 69: 100.00% (0 successes, 12 failures)\n",
      "Question 70: 8.33% (11 successes, 1 failures)\n",
      "Question 71: 8.33% (11 successes, 1 failures)\n",
      "Question 72: 100.00% (0 successes, 12 failures)\n",
      "Question 73: 25.00% (9 successes, 3 failures)\n",
      "Question 74: 66.67% (4 successes, 8 failures)\n",
      "Question 75: 8.33% (11 successes, 1 failures)\n",
      "Question 76: 100.00% (0 successes, 12 failures)\n",
      "Question 77: 100.00% (0 successes, 12 failures)\n",
      "Question 78: 8.33% (11 successes, 1 failures)\n",
      "Question 79: 8.33% (11 successes, 1 failures)\n",
      "Question 80: 100.00% (0 successes, 12 failures)\n",
      "Question 81: 8.33% (11 successes, 1 failures)\n",
      "Question 82: 8.33% (11 successes, 1 failures)\n",
      "Question 83: 100.00% (0 successes, 12 failures)\n",
      "Question 84: 50.00% (6 successes, 6 failures)\n",
      "Question 85: 50.00% (6 successes, 6 failures)\n",
      "Question 86: 8.33% (11 successes, 1 failures)\n",
      "Question 87: 91.67% (1 successes, 11 failures)\n",
      "Question 88: 100.00% (0 successes, 12 failures)\n",
      "Question 89: 75.00% (3 successes, 9 failures)\n",
      "Question 90: 8.33% (11 successes, 1 failures)\n",
      "Question 91: 8.33% (11 successes, 1 failures)\n",
      "Question 92: 100.00% (0 successes, 12 failures)\n",
      "Question 93: 8.33% (11 successes, 1 failures)\n",
      "Question 94: 8.33% (11 successes, 1 failures)\n",
      "Question 95: 8.33% (11 successes, 1 failures)\n",
      "Question 96: 8.33% (11 successes, 1 failures)\n",
      "Question 97: 66.67% (4 successes, 8 failures)\n",
      "Question 98: 100.00% (0 successes, 12 failures)\n",
      "Question 99: 91.67% (1 successes, 11 failures)\n",
      "Total successes across all targets and questions: 657\n",
      "Total failiures across all targets and questions: 543\n",
      "Number of questions with at least one success and at least one failure: 62\n"
     ]
    }
   ],
   "source": [
    "# Analyze statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Convert to numpy array for easy statistics: shape (num_target_names, num_questions)\n",
    "\n",
    "\n",
    "# matrix = np.array([correctness_matrix[name] for name in correctness_matrix])\n",
    "# Create a DataFrame directly (this handles different lengths more gracefully)\n",
    "df = pd.DataFrame.from_dict(correctness_matrix, orient='index')\n",
    "\n",
    "# Fill NaNs with 0 if you want to treat missing values as incorrect\n",
    "df = df.fillna(0).astype(int)\n",
    "\n",
    "# Convert to NumPy matrix if needed\n",
    "matrix = df.to_numpy()\n",
    "\n",
    "# 1) Success rate of each target_name across the questions\n",
    "target_failiure_rates = 1 - matrix.mean(axis=1)  # One average per row (target_name)\n",
    "\n",
    "# 2) Success rate of each question across target_names\n",
    "question_failiure_rates = 1 - matrix.mean(axis=0)  # One average per column (question/pid)\n",
    "\n",
    "# 3) For every entry, get count of successes and failures\n",
    "success_counts = matrix.sum(axis=0)  # number of target_names that got each question right\n",
    "failure_counts = len(correctness_matrix) - success_counts\n",
    "\n",
    "\n",
    "print(\"Target Failiure Rates:\")\n",
    "for name, rate in zip(correctness_matrix.keys(), target_failiure_rates):\n",
    "    print(f\"{name}: {rate:.2%}\")\n",
    "\n",
    "print(\"\\nQuestion Failiure Rates:\")\n",
    "for i, pid in enumerate(test_pids):\n",
    "    print(f\"Question {pid}: {question_failiure_rates[i]:.2%} ({int(success_counts[i])} successes, {int(failure_counts[i])} failures)\")\n",
    "\n",
    "total_correct = matrix.sum()\n",
    "total_incorrect = matrix.size - total_correct\n",
    "\n",
    "print(\"Total successes across all targets and questions:\", total_correct)\n",
    "print(\"Total failiures across all targets and questions:\", total_incorrect)\n",
    "\n",
    "\n",
    "\n",
    "# # Mask for questions with at least one success\n",
    "# questions_with_success = success_counts > 0\n",
    "\n",
    "# # Failures only for questions that had at least one success\n",
    "# failures_on_successful_questions = failure_counts[questions_with_success]\n",
    "\n",
    "# # Total failures on questions that had at least one success\n",
    "# total_failures_on_successful_questions = failures_on_successful_questions.sum()\n",
    "\n",
    "# print(\"\\nFailures on questions with at least one success:\", total_failures_on_successful_questions)\n",
    "\n",
    "# Mask: questions with at least one success AND at least one failure\n",
    "questions_with_success_and_failure = (success_counts > 0) & (failure_counts > 0)\n",
    "\n",
    "# Count them\n",
    "num_questions_with_success_and_failure = questions_with_success_and_failure.sum()\n",
    "\n",
    "print(\"Number of questions with at least one success and at least one failure:\", num_questions_with_success_and_failure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assume you already have success_counts and failure_counts as NumPy arrays\n",
    "\n",
    "# 1. Mask: questions with at least one success\n",
    "questions_with_success = success_counts > 0\n",
    "\n",
    "# 2. Get the corresponding failure counts\n",
    "failures_on_successful_questions = failure_counts[questions_with_success]\n",
    "\n",
    "# 3. Count occurrences of each failure count (as a dictionary)\n",
    "failure_distribution_dict = pd.Series(failures_on_successful_questions).value_counts().sort_index().to_dict()\n",
    "\n",
    "# 4. Plot the dictionary\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(failure_distribution_dict.keys(), failure_distribution_dict.values())\n",
    "plt.xlabel(\"Number of Failures\")\n",
    "plt.ylabel(\"Number of Questions\")\n",
    "plt.title(\"Failure Distribution (Questions with ≥1 Success)\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aayush_env)",
   "language": "python",
   "name": "aayush_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
